{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('/Users/praveena/Downloads/Assignment_2_Data/adultTrain.data', sep=',', lineterminator='\\n',header=None)\n",
    "trainData.head()\n",
    "testData=pd.read_csv('/Users/praveena/Downloads/Assignment_2_Data/adultTest.data', sep=',', lineterminator='\\n',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " trainData=trainData.drop([2,10,11], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " testData=testData.drop([2,10,11], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainData=trainData.loc[trainData[1] != ' ?']\n",
    "trainData=trainData.loc[trainData[6]!=' ?']\n",
    "trainData=trainData.loc[trainData[6]!=' Armed-Forces']\n",
    "trainData=trainData.loc[trainData[13]!=' ?']\n",
    "\n",
    "\n",
    "testData=testData.loc[testData[1] != ' ?']\n",
    "testData=testData.loc[testData[6]!=' ?']\n",
    "testData=testData.loc[testData[6]!=' Armed-Forces']\n",
    "testData=testData.loc[testData[13]!=' ?']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData[13].replace(' Mexico','Other', inplace=True)\n",
    "trainData[13].replace(' England','Other', inplace=True)\n",
    "trainData[13].replace('Others','Other', inplace=True)\n",
    "trainData[13].replace(' South','Other', inplace=True)\n",
    "trainData[13].replace(' Philippines','Other', inplace=True)\n",
    "trainData[13].replace(' Germany','Other', inplace=True)\n",
    "trainData[13].replace(' India','Other', inplace=True)\n",
    "trainData[13].replace(' Puerto-Rico','Other', inplace=True)\n",
    "trainData[13].replace(' Canada','Other', inplace=True)\n",
    "trainData[13].replace('Others','Other', inplace=True)\n",
    "trainData[13].replace(' El-Salvador','Other', inplace=True)\n",
    "trainData[13].replace(' Cuba','Other', inplace=True)\n",
    "trainData[13].replace(' Germany','Other', inplace=True)\n",
    "trainData[13].replace(' Jamaica','Other', inplace=True)\n",
    "trainData[13].replace(' Portugal','Other', inplace=True)\n",
    "trainData[13].replace(' Haiti','Other', inplace=True)\n",
    "trainData[13].replace(' Iran','Other', inplace=True)\n",
    "trainData[13].replace(' Taiwan','Other', inplace=True)\n",
    "trainData[13].replace(' Germany','Other', inplace=True)\n",
    "trainData[13].replace(' Columbia','Other', inplace=True)\n",
    "trainData[13].replace(' Poland','Other', inplace=True)\n",
    "trainData[13].replace(' Japan','Other', inplace=True)\n",
    "trainData[13].replace(' Guatemala','Other', inplace=True)\n",
    "trainData[13].replace(' Vietnam','Other', inplace=True)\n",
    "trainData[13].replace(' Dominican-Republic','Other', inplace=True)\n",
    "trainData[13].replace(' Italy','Other', inplace=True)\n",
    "trainData[13].replace(' China','Other', inplace=True)\n",
    "trainData[13].replace(' Nicaragua','Other', inplace=True)\n",
    "trainData[13].replace(' Greece','Other', inplace=True)\n",
    "trainData[13].replace(' Ecuador','Other', inplace=True)\n",
    "trainData[13].replace(' France','Other', inplace=True)\n",
    "trainData[13].replace(' Ireland','Other', inplace=True)\n",
    "trainData[13].replace(' Hong','Other', inplace=True)\n",
    "trainData[13].replace(' Trinadad&Tobago','Other', inplace=True)\n",
    "trainData[13].replace(' Cambodia','Other', inplace=True)\n",
    "trainData[13].replace(' Laos','Other', inplace=True)\n",
    "trainData[13].replace(' Thailand','Other', inplace=True)\n",
    "trainData[13].replace(' Yugoslavia','Other', inplace=True)\n",
    "trainData[13].replace(' Outlying-US(Guam-USVI-etc)','Other', inplace=True)\n",
    "trainData[13].replace(' Hungary','Other', inplace=True)\n",
    "trainData[13].replace(' Honduras','Other', inplace=True)\n",
    "trainData[13].replace(' Scotland','Other', inplace=True)\n",
    "trainData[13].replace(' Thailand','Other', inplace=True)\n",
    "trainData[13].replace(' Holand-Netherlands','Other', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "testData[13].replace(' Mexico','Other', inplace=True)\n",
    "testData[13].replace(' England','Other', inplace=True)\n",
    "testData[13].replace('Others','Other', inplace=True)\n",
    "testData[13].replace(' South','Other', inplace=True)\n",
    "testData[13].replace(' Philippines','Other', inplace=True)\n",
    "testData[13].replace(' Germany','Other', inplace=True)\n",
    "testData[13].replace(' India','Other', inplace=True)\n",
    "testData[13].replace(' Puerto-Rico','Other', inplace=True)\n",
    "testData[13].replace(' Canada','Other', inplace=True)\n",
    "testData[13].replace('Others','Other', inplace=True)\n",
    "testData[13].replace(' El-Salvador','Other', inplace=True)\n",
    "testData[13].replace(' Cuba','Other', inplace=True)\n",
    "testData[13].replace(' Germany','Other', inplace=True)\n",
    "testData[13].replace(' Jamaica','Other', inplace=True)\n",
    "testData[13].replace(' Portugal','Other', inplace=True)\n",
    "testData[13].replace(' Haiti','Other', inplace=True)\n",
    "testData[13].replace(' Iran','Other', inplace=True)\n",
    "testData[13].replace(' Taiwan','Other', inplace=True)\n",
    "testData[13].replace(' Germany','Other', inplace=True)\n",
    "testData[13].replace(' Columbia','Other', inplace=True)\n",
    "testData[13].replace(' Poland','Other', inplace=True)\n",
    "testData[13].replace(' Japan','Other', inplace=True)\n",
    "testData[13].replace(' Guatemala','Other', inplace=True)\n",
    "testData[13].replace(' Vietnam','Other', inplace=True)\n",
    "testData[13].replace(' Dominican-Republic','Other', inplace=True)\n",
    "testData[13].replace(' Italy','Other', inplace=True)\n",
    "testData[13].replace(' China','Other', inplace=True)\n",
    "testData[13].replace(' Nicaragua','Other', inplace=True)\n",
    "testData[13].replace(' Greece','Other', inplace=True)\n",
    "testData[13].replace(' Ecuador','Other', inplace=True)\n",
    "testData[13].replace(' France','Other', inplace=True)\n",
    "testData[13].replace(' Ireland','Other', inplace=True)\n",
    "testData[13].replace(' Hong','Other', inplace=True)\n",
    "testData[13].replace(' Trinadad&Tobago','Other', inplace=True)\n",
    "testData[13].replace(' Cambodia','Other', inplace=True)\n",
    "testData[13].replace(' Laos','Other', inplace=True)\n",
    "testData[13].replace(' Thailand','Other', inplace=True)\n",
    "testData[13].replace(' Yugoslavia','Other', inplace=True)\n",
    "testData[13].replace(' Outlying-US(Guam-USVI-etc)','Other', inplace=True)\n",
    "testData[13].replace(' Hungary','Other', inplace=True)\n",
    "testData[13].replace(' Honduras','Other', inplace=True)\n",
    "testData[13].replace(' Scotland','Other', inplace=True)\n",
    "testData[13].replace(' Thailand','Other', inplace=True)\n",
    "testData[13].replace(' Holand-Netherlands','Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData=trainData.replace({'<=50K': 0, '>50K':1}, regex=True)\n",
    "testData=testData.replace({'<=50K': 0, '>50K':1}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData1 = pd.get_dummies(trainData.drop(trainData.columns[len(trainData.columns)-1],axis=1))\n",
    "\n",
    "testData1 = pd.get_dummies(testData.drop(testData.columns[len(testData.columns)-1],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target1 = trainData[14]\n",
    "target2 = testData[14]\n",
    "\n",
    "\n",
    "\n",
    "X_train =trainData1\n",
    "y_train =testData1 \n",
    "X_test= target1\n",
    "y_test=target2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(trainData1, target1, random_state=0)\n",
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split(testData1, target2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-979009fb6e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 576\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural Network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainData1, target1, test_size=0.3, random_state=0)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(testData1, target2, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "clf = svm.SVC(kernel='linear', C = 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, predicted)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, predicted))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
